{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14830ba4-9e04-49bd-81e3-9d8420786d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39be4749-1b72-4944-88c2-716829295510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_points(face_landmarks):\n",
    "  # Save the landmark coordinates for  the eyes\n",
    "  right_landmarks = [33, 160, 157, 133, 153, 144]\n",
    "  right_eye_points = []\n",
    "  for landmark in right_landmarks:\n",
    "    right_eye_points.append([face_landmarks[landmark].x,\n",
    "                            face_landmarks[landmark].y,\n",
    "                            face_landmarks[landmark].z])\n",
    "\n",
    "  left_landmarks = [362, 385, 388, 263, 373, 380]\n",
    "  left_eye_points = []\n",
    "  for landmark in left_landmarks:\n",
    "    left_eye_points.append([face_landmarks[landmark].x,\n",
    "                            face_landmarks[landmark].y,\n",
    "                            face_landmarks[landmark].z])\n",
    "\n",
    "  # Save the landmark coordinates for  the mouth\n",
    "  mouth_landmarks = [78, 81, 13, 311, 308, 402, 14, 178]\n",
    "  mouth_points = []\n",
    "  for landmark in mouth_landmarks:\n",
    "    mouth_points.append([face_landmarks[landmark].x,\n",
    "                            face_landmarks[landmark].y,\n",
    "                            face_landmarks[landmark].z])\n",
    "  return right_eye_points, left_eye_points, mouth_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab917b0-eb29-4f93-b7f1-726dd44ec586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EARs(l_p, r_p):\n",
    "\n",
    "  p2_p6 = np.linalg.norm(l_p[1]-l_p[5])\n",
    "  p3_p5 = np.linalg.norm(l_p[2]-l_p[4])\n",
    "  p1_p4 = np.linalg.norm(l_p[0]-l_p[3])\n",
    "  left_EAR = (p2_p6 + p3_p5)/(2*p1_p4)\n",
    "\n",
    "  p2_p6 = np.linalg.norm(r_p[1]-r_p[5])\n",
    "  p3_p5 = np.linalg.norm(r_p[2]-r_p[4])\n",
    "  p1_p4 = np.linalg.norm(r_p[0]-r_p[3])\n",
    "  right_EAR = (p2_p6 + p3_p5)/(2*p1_p4)\n",
    "\n",
    "  return left_EAR, right_EAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5ca825-be22-4d71-8bea-5d5d3deb059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAR(m_p):\n",
    "\n",
    "  p2_p8 = np.linalg.norm(m_p[1]-m_p[7])\n",
    "  p3_p7= np.linalg.norm(m_p[2]-m_p[6])\n",
    "  p4_p6 = np.linalg.norm(m_p[3]-m_p[5])\n",
    "  p1_p5 = np.linalg.norm(m_p[0]-m_p[4])\n",
    "  MAR = (p2_p8 + p3_p7 + p4_p6)/(2*p1_p5)\n",
    "\n",
    "  return MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bafe2ba-a6a8-4101-bffe-220c6f23108a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1702471389.107217    9315 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1702471389.111127    9473 gl_context.cc:344] GL version: 3.2 (OpenGL ES 3.2 Mesa 21.2.6), renderer: Mesa Intel(R) UHD Graphics 620 (KBL GT2)\n",
      "W0000 00:00:1702471389.112291    9315 face_landmarker_graph.cc:174] Sets FaceBlendshapesGraph acceleration to xnnpack by default.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mouth_landmarks = [78, 81, 13, 311, 308, 402, 14, 178]\n",
    "left_landmarks = [362, 385, 388, 263, 373, 380]\n",
    "right_landmarks = [33, 160, 157, 133, 153, 144]\n",
    "index_list = mouth_landmarks + left_landmarks + right_landmarks\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
    "FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = FaceLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "i = 0\n",
    "with FaceLandmarker.create_from_options(options) as landmarker:\n",
    "    while True:\n",
    "        i += 1\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        height, width, _ = frame.shape\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "\n",
    "        results = landmarker.detect(mp_image)\n",
    "\n",
    "        if results.face_landmarks is not None:\n",
    "            face_landmarks_list = results.face_landmarks\n",
    "            for idx in range(len(face_landmarks_list)):\n",
    "                face_landmarks = face_landmarks_list[idx]\n",
    "                face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "                face_landmarks_proto.landmark.extend([\n",
    "                    landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks])\n",
    "                for index in index_list:\n",
    "                    x = int(face_landmarks[index].x * width)\n",
    "                    y = int(face_landmarks[index].y * height)\n",
    "                    cv2.circle(frame, (x, y), 2, (0, 255, 0), 1)\n",
    "            \n",
    "        if i % 7 == 0:\n",
    "            try:\n",
    "                right_eye_points, left_eye_points, mouth_points = get_face_points(results.face_landmarks[0])\n",
    "            except:\n",
    "                right_eye_points = right_eye_points\n",
    "                left_eye_points = left_eye_points \n",
    "                mouth_points = mouth_points\n",
    "            left_EAR, right_EAR = get_EARs(np.array(left_eye_points), np.array(right_eye_points))\n",
    "            MAR = get_MAR(np.array(mouth_points))\n",
    "        if i > 7:\n",
    "            cv2.putText(frame,f\"Left EAR: {left_EAR:.2f}\",(30, 30),cv2.FONT_HERSHEY_DUPLEX,0.7,(0, 255, 255),1,)\n",
    "            cv2.putText(frame,f\"Right EAR: {right_EAR:.2f}\",(30, 60),cv2.FONT_HERSHEY_DUPLEX,0.7,(0, 255, 255),1,)\n",
    "            cv2.putText(frame,f\"MAR: {MAR:.2f}\",(30, 90),cv2.FONT_HERSHEY_DUPLEX,0.7,(0, 255, 255),1,)\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fc033-0bf3-4ccf-b412-a32dd09b3145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15111a55-d77e-44d1-86f8-4651657d54ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8e061-c179-4607-8718-a25b6f6e7e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
