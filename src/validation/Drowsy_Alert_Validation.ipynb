{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Driving Drowsiness Detection** - Validation\n",
        "\n",
        "----------\n",
        "*Master's in Automation and Robotics - ETSII (UPM)*\\\n",
        "**Subject:** Computer Vision\\\n",
        "**Course:** 2023-24\\\n",
        "**Student Name (ID):**\n",
        "- Ivonne Quishpe (23146)\n",
        "- Gustavo Maldonado (23102)\n",
        "- Jorge Guijarro (23075)\n",
        "- Micaela Cabrera (23023)\n",
        "- Josep Mª Barberá (17048)\n",
        "\n",
        "**Date:** December, 6\n",
        "\n",
        "------------\n",
        "This Notebook uses the drowsiness detection system on a set of short videos to validate its correct operation. The test set used comes from this [GitHub repository](https://github.com/EsraKavalci/Sivas-University-of-Science-and-Technology-Driver-Drowsiness-Dataset/tree/main/SUST%20Driver%20Drowsiness%20Dataset). For simplicity only 100 videos of each type have been used. The results are shown in the readme as well as in the final report of this project."
      ],
      "metadata": {
        "id": "Pec4_fVoPgr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "drxs7kTUdweG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  if DATA_IS_LOADED:\n",
        "    pass\n",
        "except:\n",
        "    !pip install mediapipe\n",
        "    !wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\n",
        "DATA_IS_LOADED = True\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "from mediapipe import solutions\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import glob\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKvsQrbKdnrc",
        "outputId": "2faf2ae7-f7f3-45ce-af02-39e8d447276b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eye_landmarks_num = 6   # 4 or 6\n",
        "\n",
        "if eye_landmarks_num == 4:\n",
        "    left_landmarks = [362, 386, 263, 374]\n",
        "    right_landmarks = [33, 158, 133, 153]\n",
        "else:\n",
        "    left_landmarks = [362, 384, 386, 263, 374, 381]\n",
        "    right_landmarks = [33, 160, 158, 133, 153, 144]\n",
        "    if eye_landmarks_num != 6:\n",
        "        print(\"Number of landmarks per eye should be 4 or 6. Setting it to 6 by default...\")\n",
        "\n",
        "mouth_landmarks = [78, 81, 13, 311, 308, 402, 14, 178]"
      ],
      "metadata": {
        "id": "Q3ZRGJnPduv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_face_points(face_landmarks):\n",
        "    # Save the landmark coordinates for  the eyes\n",
        "    right_eye_points = []\n",
        "    for landmark in right_landmarks:\n",
        "        right_eye_points.append([face_landmarks[landmark].x,\n",
        "                            face_landmarks[landmark].y,\n",
        "                            face_landmarks[landmark].z])\n",
        "\n",
        "    left_eye_points = []\n",
        "    for landmark in left_landmarks:\n",
        "        left_eye_points.append([face_landmarks[landmark].x,\n",
        "                            face_landmarks[landmark].y,\n",
        "                            face_landmarks[landmark].z])\n",
        "\n",
        "    # Save the landmark coordinates for  the mouth\n",
        "    mouth_points = []\n",
        "    for landmark in mouth_landmarks:\n",
        "        mouth_points.append([face_landmarks[landmark].x,\n",
        "                            face_landmarks[landmark].y,\n",
        "                            face_landmarks[landmark].z])\n",
        "    return right_eye_points, left_eye_points, mouth_points"
      ],
      "metadata": {
        "id": "jG-fyWXey5MU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_EARs(l_p, r_p):\n",
        "    if eye_landmarks_num == 4:\n",
        "        p2_p4 = np.linalg.norm(l_p[1]-l_p[3])\n",
        "        p1_p3 = np.linalg.norm(l_p[0]-l_p[2])\n",
        "        left_EAR = (p2_p4)/(p1_p3)\n",
        "\n",
        "        p2_p4 = np.linalg.norm(r_p[1]-r_p[3])\n",
        "        p1_p3 = np.linalg.norm(r_p[0]-r_p[2])\n",
        "        right_EAR = (p2_p4)/(p1_p3)\n",
        "    else:\n",
        "        p2_p6 = np.linalg.norm(l_p[1]-l_p[5])\n",
        "        p3_p5 = np.linalg.norm(l_p[2]-l_p[4])\n",
        "        p1_p4 = np.linalg.norm(l_p[0]-l_p[3])\n",
        "        left_EAR = (p2_p6 + p3_p5)/(2*p1_p4)\n",
        "\n",
        "        p2_p6 = np.linalg.norm(r_p[1]-r_p[5])\n",
        "        p3_p5 = np.linalg.norm(r_p[2]-r_p[4])\n",
        "        p1_p4 = np.linalg.norm(r_p[0]-r_p[3])\n",
        "        right_EAR = (p2_p6 + p3_p5)/(2*p1_p4)\n",
        "\n",
        "    return left_EAR, right_EAR"
      ],
      "metadata": {
        "id": "n8WXQq1ay5Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_MAR(m_p):\n",
        "  p2_p8 = np.linalg.norm(m_p[1]-m_p[7])\n",
        "  p3_p7= np.linalg.norm(m_p[2]-m_p[6])\n",
        "  p4_p6 = np.linalg.norm(m_p[3]-m_p[5])\n",
        "  p1_p5 = np.linalg.norm(m_p[0]-m_p[4])\n",
        "  MAR = (p2_p8 + p3_p7 + p4_p6)/(2*p1_p5)\n",
        "  return MAR"
      ],
      "metadata": {
        "id": "Bg6jg5rcy5Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_drowsiness(left_EAR, right_EAR, MAR, data):\n",
        "    left_score, right_score, mouth_score, eyes_tag, yawn_tag, alert, frames_sleep, frames_awake = data\n",
        "\n",
        "    ## Increase score if eyes closed, decrease otherwise\n",
        "    if (left_EAR < 0.15):\n",
        "        left_score += 1\n",
        "    else:\n",
        "        left_score -= 1\n",
        "\n",
        "    if (right_EAR < 0.15):\n",
        "        right_score += 1\n",
        "    else:\n",
        "        right_score -= 1\n",
        "\n",
        "    ## Increase score if mouth open, decrease otherwise\n",
        "    if (MAR > 0.17):\n",
        "        mouth_score += 1\n",
        "    else:\n",
        "        mouth_score -= 1\n",
        "\n",
        "    ## Scores can't be negative\n",
        "    if (left_score < 0):\n",
        "        left_score = 0\n",
        "    if (right_score < 0):\n",
        "        right_score = 0\n",
        "    if (mouth_score < 0):\n",
        "        mouth_score = 0\n",
        "\n",
        "    ## Un parpadeo normal equivale a 9 frames (300 ms si se toman 30 fps).\n",
        "    if (left_score > 12 and right_score > 12):\n",
        "        eyes_tag = \"closed\"\n",
        "    else:\n",
        "        eyes_tag = \"open\"\n",
        "\n",
        "    ## Si la boca está abierta más de tres segundos se considera bostezo\n",
        "    if (mouth_score > 70):\n",
        "        yawn_tag = True\n",
        "    else:\n",
        "        yawn_tag = False\n",
        "\n",
        "    if (eyes_tag == \"closed\" or yawn_tag == True):\n",
        "        alert += 1\n",
        "        frames_sleep += 1\n",
        "    else:\n",
        "        alert -= 1\n",
        "        if (alert < 0):\n",
        "            alert = 0\n",
        "        frames_awake += 1\n",
        "    return [left_score, right_score, mouth_score, eyes_tag, yawn_tag, alert, frames_sleep, frames_awake]"
      ],
      "metadata": {
        "id": "ErojqJ9Ny5GL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_mesh(path):\n",
        "    # path = \"/home/josep/Webcam/my.webm\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    index_list = mouth_landmarks + left_landmarks + right_landmarks\n",
        "\n",
        "    BaseOptions = mp.tasks.BaseOptions\n",
        "    FaceLandmarker = mp.tasks.vision.FaceLandmarker\n",
        "    FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions\n",
        "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "    options = FaceLandmarkerOptions(\n",
        "        base_options=BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task'),\n",
        "        running_mode=VisionRunningMode.IMAGE)\n",
        "\n",
        "    i = 0\n",
        "    prev_left_EAR, prev_right_EAR, prev_MAR = 0,0,0\n",
        "    data = [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    alert_time = 0\n",
        "    alert_i = 0\n",
        "    right_eye_points = [[0.5324623584747314, 0.5747805833816528, 0.004818260669708252],\n",
        "                        [0.5445109009742737, 0.5637452006340027, -0.0011025648564100266],\n",
        "                        [0.5702856183052063, 0.5580060482025146, -0.0021580627653747797],\n",
        "                        [0.5986989736557007, 0.5627603530883789, 0.023030918091535568],\n",
        "                        [0.5674318075180054, 0.5806047916412354, 0.004358564969152212],\n",
        "                        [0.5431403517723083, 0.5771798491477966, 0.00291746249422431]]\n",
        "\n",
        "    left_eye_points =  [[0.37691813707351685, 0.5854962468147278, 0.002876535290852189],\n",
        "                        [0.3939114511013031, 0.5759596824645996, -0.014068366028368473],\n",
        "                        [0.4192018210887909, 0.5710769891738892, -0.016808023676276207],\n",
        "                        [0.4473620355129242, 0.5828512907028198, -0.004112580791115761],\n",
        "                        [0.42484530806541443, 0.592927098274231, -0.010263157077133656],\n",
        "                        [0.3993476927280426, 0.597295880317688, -0.0077733625657856464]]\n",
        "    mouth_points = [[0.46936848759651184, 0.8040176630020142, 0.005104257259517908],\n",
        "                    [0.49690064787864685, 0.7995496392250061, -0.012885571457445621],\n",
        "                    [0.5246973037719727, 0.7988075017929077, -0.0167536623775959],\n",
        "                    [0.5486900210380554, 0.7920270562171936, -0.006666502915322781],\n",
        "                    [0.572444498538971, 0.7885196208953857, 0.017038118094205856],\n",
        "                    [0.5485737919807434, 0.7921735644340515, -0.0028128675185143948],\n",
        "                    [0.5245987176895142, 0.7992886304855347, -0.012132205069065094],\n",
        "                    [0.4968000650405884, 0.8000173568725586, -0.009343835525214672]]\n",
        "\n",
        "    with FaceLandmarker.create_from_options(options) as landmarker:\n",
        "        while True:\n",
        "            i += 1\n",
        "            ret, frame = cap.read()\n",
        "            if ret == False:\n",
        "                break\n",
        "            height, width, _ = frame.shape\n",
        "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
        "            results = landmarker.detect(mp_image)\n",
        "\n",
        "            if results.face_landmarks is not None:\n",
        "                face_landmarks_list = results.face_landmarks\n",
        "                for idx in range(len(face_landmarks_list)):\n",
        "                    face_landmarks = face_landmarks_list[idx]\n",
        "                    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "                    face_landmarks_proto.landmark.extend([\n",
        "                        landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks])\n",
        "                    for index in index_list:\n",
        "                        x = int(face_landmarks[index].x * width)\n",
        "                        y = int(face_landmarks[index].y * height)\n",
        "                        cv2.circle(frame, (x, y), 2, (0, 255, 0), 1)\n",
        "\n",
        "            try:\n",
        "                right_eye_points, left_eye_points, mouth_points = get_face_points(results.face_landmarks[0])\n",
        "            except:\n",
        "                right_eye_points = right_eye_points\n",
        "                left_eye_points = left_eye_points\n",
        "                mouth_points = mouth_points\n",
        "\n",
        "            left_EAR, right_EAR = get_EARs(np.array(left_eye_points), np.array(right_eye_points))\n",
        "            MAR = get_MAR(np.array(mouth_points))\n",
        "            # print(left_EAR, right_EAR, MAR)\n",
        "\n",
        "            data = check_drowsiness(left_EAR, right_EAR, MAR, data)\n",
        "            _, _, _, eyes_tag, yawn_tag, alert, frames_sleep, frames_awake = data\n",
        "\n",
        "            if (alert - alert_i > 0):\n",
        "                alert_time += 1\n",
        "                alert_i = alert\n",
        "            # cv2_imshow(frame)\n",
        "            # print(alert, alert - alert_i)\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    return alert_time"
      ],
      "metadata": {
        "id": "8XwXbxn-y5Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_files = r\"/content/drive/MyDrive/Github_Videos/*\"\n",
        "folders = glob.glob(path_files)"
      ],
      "metadata": {
        "id": "NRABfEmlj5-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-TNKX5RJOAkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for folder in folders:\n",
        "  files = glob.glob(folder + \"/*.mp4\")\n",
        "  for my_file in files:\n",
        "    result = face_mesh(my_file)\n",
        "    results.append(result)\n",
        "    print(f\"Processing file: {my_file} with results= {result}\\n\")"
      ],
      "metadata": {
        "id": "bUTYE4LjlEdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QrMRB0Kt2u1S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}